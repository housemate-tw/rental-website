# Claude Scraper 專案總覽

**文件版本**: v1.0
**建立日期**: 2025-10-20
**負責 AI**: Claude (Sonnet 4.5)
**專案狀態**: 規劃階段

---

## 1. 專案背景 (Project Background)

### 1.1 原始專案目標

自動化抓取公開 Facebook 租屋社團的貼文，進行結構化處理，產出可用於資料分析的 JSON 資料，並提供一個現代化的網頁應用程式供使用者瀏覽。

**核心價值主張**:
- 將分散在 Facebook 社團的租屋資訊集中化
- 透過結構化提取關鍵資訊（租金、地區、房型等）
- 提供比 Facebook 更好的搜尋和篩選體驗

### 1.2 專案歷史與現況

**Phase 1 - Gemini 主導階段** (2025-10-11 ~ 2025-10-18)

Gemini 負責建立了整個專案的基礎架構：

1. **資料抓取**: 使用 GraphQL API 方式抓取 Facebook 貼文
2. **資料處理**: 建立 `save_rental_v8.py` 進行結構化存檔
3. **Web App**: 建立 Next.js 專案提供前端展示
4. **資料去重**: 實作跨檔案的資料指紋比對

**成果**:
- ✅ 資料結構設計完善（v8.0 規格）
- ✅ 存檔機制穩定（File Lock 防衝突）
- ✅ 有成功抓取並存入資料（`/data_v8/2025-10-14.jsonl`, `2025-10-18.jsonl`）

**問題**:
- ❌ Token 消耗過快（AI API 成本高）
- ❌ API 回應空白時無法處理
- ❌ 流程中斷後無法定位卡點
- ❌ 從未成功完成一次大量連續抓取
- ❌ 缺乏進度可視化與錯誤追蹤

**Phase 2 - Claude 接管階段** (2025-10-20 ~)

Claude 接手解決爬蟲穩定性問題，目標是建立一個：
- 零 AI Token 消耗的純程式化爬蟲
- 具備完整錯誤處理與恢復機制
- 可視化監控與進度追蹤
- 斷點續傳能力

---

## 2. AI 協作分工 (AI Collaboration Model)

### 2.1 Gemini 的職責範圍

**已完成且不變動的部分**:
- ✅ 資料結構定義（v8.0 schema）
- ✅ `save_rental_v8.py` 存檔腳本
- ✅ Next.js Web App 架構
- ✅ API Route (`/api/rentals`)

**Gemini 繼續負責**:
- 前端 UI/UX 優化
- 資料結構化的 PRD 規則維護
- Web App 功能擴展

### 2.2 Claude 的職責範圍

**新建且完全獨立的部分**:
- ✅ Facebook 爬蟲系統（使用 Playwright）
- ✅ 進度追蹤與狀態管理
- ✅ 錯誤處理與自動重試
- ✅ 監控儀表板
- ✅ 完整的技術文檔

**工作目錄**: `/Users/sabrina/Documents/housemate-finder-app/claude_scraper/`

**整合點**: 呼叫 Gemini 的 `save_rental_v8.py` 進行資料存檔

### 2.3 協作原則

1. **非破壞性**: Claude 不修改 Gemini 的任何檔案
2. **獨立性**: Claude 的程式碼完全獨立，可單獨運行或移除
3. **可替代性**: 若 Claude 方案失敗，可切換到其他 AI 或人工接手
4. **文檔優先**: 所有決策都有文檔記錄，方便未來追溯

---

## 3. 技術棧 (Technology Stack)

### 3.1 Claude Scraper 使用的技術

| 層級 | 技術 | 用途 |
|------|------|------|
| **瀏覽器自動化** | Playwright (Python) | 模擬真實瀏覽器操作 |
| **程式語言** | Python 3.9+ | 主要開發語言 |
| **狀態管理** | JSON 檔案 | 記錄爬取進度與狀態 |
| **日誌系統** | Python logging | 記錄運行日誌 |
| **錯誤處理** | 自定義重試機制 | 處理網路錯誤與 timeout |
| **資料存檔** | 呼叫 `save_rental_v8.py` | 整合 Gemini 的存檔系統 |

### 3.2 與 Gemini 系統的整合

```
Claude Scraper (爬取) → save_rental_v8.py (存檔) → data_v8/*.jsonl (資料) → Next.js API (讀取) → 前端 (展示)
```

**整合介面**:
- Claude 產出：原始貼文文本
- 呼叫：`python3 save_rental_v8.py [參數...]`
- Gemini 產出：結構化 JSON 存入 `.jsonl`

---

## 4. 專案目標 (Project Goals)

### 4.1 核心目標

**主要目標**: 建立一個穩定、可靠、可監控的 Facebook 爬蟲系統

**具體指標**:
1. ✅ 能夠連續運行 2+ 小時不中斷
2. ✅ 成功抓取 500+ 則貼文
3. ✅ 錯誤率 < 5%
4. ✅ 所有錯誤都有日誌記錄
5. ✅ 中斷後可從上次位置繼續

### 4.2 次要目標

1. **可視化監控**: 即時了解爬取進度
2. **自動化排程**: 可設定定時執行
3. **資料品質**: 去重、驗證、清洗
4. **可配置性**: 透過設定檔調整參數

### 4.3 非目標 (Non-Goals)

以下事項**不在** Claude Scraper 的範圍內：
- ❌ 修改資料結構（由 Gemini 負責）
- ❌ 前端 UI 開發（由 Gemini 負責）
- ❌ 資料分析功能（未來可能需求）
- ❌ 多平台支援（目前只支援 Facebook）

---

## 5. 成功標準 (Success Criteria)

### 5.1 技術標準

| 指標 | 標準 | 測試方法 |
|------|------|----------|
| **穩定性** | 連續運行 2 小時無崩潰 | 壓力測試 |
| **成功率** | 95% 以上貼文成功抓取 | 統計日誌 |
| **恢復能力** | 中斷後 5 分鐘內可恢復 | 模擬中斷 |
| **可追蹤性** | 100% 錯誤有日誌 | 檢查 logs/ |
| **效能** | 每分鐘處理 10+ 則貼文 | 效能測試 |

### 5.2 商業標準

1. **使用者可自行運行**: 不需要 AI 協助即可啟動爬蟲
2. **錯誤可自行診斷**: 透過日誌和文檔可定位問題
3. **資料品質穩定**: 產出的資料符合 v8.0 規格

---

## 6. 風險與緩解措施 (Risks & Mitigations)

### 6.1 已識別風險

| 風險 | 影響 | 機率 | 緩解措施 |
|------|------|------|----------|
| Facebook 封鎖帳號 | 高 | 中 | 降低爬取速度、模擬真人行為 |
| Facebook UI 改版 | 高 | 低 | 使用多種 selector、定期測試 |
| 網路不穩定 | 中 | 高 | 自動重試、斷點續傳 |
| Playwright 相容性 | 中 | 低 | 鎖定版本、充分測試 |
| 資料格式變化 | 中 | 低 | 彈性解析、日誌記錄異常 |

### 6.2 退出策略

如果 Claude Scraper 最終無法達成目標：

1. **所有文檔完整**: 可供其他開發者或 AI 接手
2. **程式碼獨立**: 刪除 `claude_scraper/` 不影響 Gemini 系統
3. **可回退**: 回到 Gemini 的 GraphQL 方案
4. **知識累積**: 至少明確了「什麼方法行不通」

---

## 7. 時程規劃 (Timeline)

### Phase 1: 規劃與設計 (已完成 2025-10-20)
- ✅ 專案總覽文件
- ⏳ 問題分析文件
- ⏳ 解決方案設計文件
- ⏳ 系統架構文件
- ⏳ 實作計劃文件

### Phase 2: 核心開發 (預計 1-2 天)
- ⏳ 基礎爬蟲實作
- ⏳ 狀態管理系統
- ⏳ 錯誤處理機制
- ⏳ 整合 save_rental_v8.py

### Phase 3: 測試與優化 (預計 1 天)
- ⏳ 功能測試
- ⏳ 穩定性測試
- ⏳ 效能優化

### Phase 4: 監控與文檔 (預計 0.5 天)
- ⏳ 監控系統
- ⏳ 使用手冊
- ⏳ 故障排除指南

---

## 8. 文檔導航 (Documentation Index)

建議閱讀順序：

1. **00_project_overview.md** (本文件) - 了解整體概況
2. **01_problem_analysis.md** - 了解為何需要 Claude 接手
3. **02_solution_design.md** - 了解技術方案選擇
4. **03_architecture.md** - 了解系統架構
5. **04_implementation_plan.md** - 了解實作步驟
6. **05_api_reference.md** - 開發時查閱
7. **06_troubleshooting.md** - 遇到問題時查閱
8. **99_changelog.md** - 追蹤變更歷史

---

## 9. 聯絡與協作 (Contact & Collaboration)

### 9.1 文檔更新原則

- 所有重大決策都要更新相關文檔
- 每次程式碼變更都要更新 `99_changelog.md`
- 遇到新問題要更新 `06_troubleshooting.md`

### 9.2 AI 協作模式

如果未來需要其他 AI 接手：

1. 從本文件開始閱讀
2. 檢查 `99_changelog.md` 了解最新狀態
3. 查看 `logs/` 了解運行歷史
4. 查看 `state/` 了解當前進度

---

## 10. 附錄 (Appendix)

### 10.1 關鍵路徑

```
/Users/sabrina/Documents/
├── data_v8/                          # Gemini 的資料存放處
├── rental_project/                   # Gemini 的工作目錄
│   └── save_rental_v8.py            # Claude 需要呼叫的腳本
└── housemate-finder-app/            # 專案根目錄
    ├── claude_scraper/              # Claude 的獨立工作目錄
    │   ├── docs/                    # 本文件所在位置
    │   ├── src/                     # Claude 的程式碼
    │   ├── config/                  # 配置檔
    │   ├── logs/                    # 運行日誌
    │   └── state/                   # 狀態檔案
    └── src/                         # Gemini 的 Next.js 程式碼
```

### 10.2 專案哲學

本專案採用 **Regret Minimization Framework**：

> "當我們回顧這個專案時，我們不會後悔『花太多時間寫文檔』，但會後悔『沒有足夠的文檔導致無法維護』。"

因此我們：
- ✅ 文檔優先於程式碼
- ✅ 清晰優先於簡潔
- ✅ 可維護性優先於快速交付
- ✅ 獨立性優先於緊密整合

---

**文件結束**

下一步請閱讀: `01_problem_analysis.md`
