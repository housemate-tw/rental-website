# 問題分析：為何需要 Claude 接手爬蟲系統

**文件版本**: v1.0
**建立日期**: 2025-10-20
**負責 AI**: Claude (Sonnet 4.5)

---

## 1. 執行摘要 (Executive Summary)

Gemini 的 GraphQL + MCP 方案在概念上是可行的，並已證明能夠產出正確格式的資料。然而，在實際大規模執行時遇到了**致命的穩定性問題**，導致從未成功完成一次完整的批量抓取。

**核心問題**: 不是「技術路線錯誤」，而是「執行穩定性不足」。

---

## 2. Gemini 方案回顧

### 2.1 技術架構

```
使用者指令 → Gemini AI
              ↓
        chrome-devtools-mcp (瀏覽器控制)
              ↓
        Facebook GraphQL API
              ↓
        Gemini AI (結構化處理)
              ↓
        save_rental_v8.py (存檔)
              ↓
        data_v8/*.jsonl (資料儲存)
```

### 2.2 理論優勢

1. **直接存取 API**: 繞過 UI 解析的複雜性
2. **結構化能力強**: Gemini 擅長文本結構化
3. **整合性高**: 抓取 + 處理 + 存檔一條龍

### 2.3 實際成果

**成功之處**:
- ✅ 建立了完整的資料結構（v8.0 schema）
- ✅ 實作了防衝突的存檔機制（File Lock）
- ✅ 有成功存入小批量資料（2025-10-14: 5 筆, 2025-10-18: 1 筆）

**證據**: `/Users/sabrina/Documents/data_v8/` 中的 `.jsonl` 檔案格式正確且完整。

---

## 3. 致命缺陷分析

### 3.1 問題一：Token 消耗過快

**現象**:
- 執行爬蟲任務時 Token 燒得太快
- 成本隨著抓取數量線性增加

**根本原因**:
```
每一則貼文的處理流程：
1. Gemini 呼叫 MCP 抓取貼文 → 消耗 Token
2. Gemini 閱讀貼文內容 → 消耗 Token
3. Gemini 結構化處理 → 消耗 Token
4. Gemini 呼叫存檔腳本 → 消耗 Token
5. 重複 500 次... → 總 Token 爆炸
```

**影響**:
- 💰 高昂的 API 成本
- ⏱️ 處理速度慢（AI 推理有延遲）
- 🚫 可能觸及 API 使用上限

### 3.2 問題二：API 回應空白無法處理

**現象**:
- 有時 GraphQL API 回應空白
- Gemini 沒有抓回任何東西
- 整個流程就停下來

**根本原因**:
1. **網路不穩定**: Facebook API 偶爾會 timeout 或回應異常
2. **缺乏重試機制**: Gemini 在對話式互動中難以實作複雜的重試邏輯
3. **錯誤處理不足**: 無法區分「暫時性錯誤」vs「永久性錯誤」

**實際案例**:
```
[使用者報告]
"有時會顯示 API 回應空白，他沒有抓回任何東西，
所以整個流程就停下來"
```

### 3.3 問題三：無法定位卡點

**現象**:
- 流程中斷後，不清楚卡在哪一步
- 整個專案就卡死了

**根本原因**:
1. **缺乏狀態記錄**: 沒有持久化的進度追蹤
2. **日誌不完整**: AI 對話歷史不等於系統日誌
3. **不可恢復**: 中斷後無法從上次位置繼續

**對比傳統程式**:
| 特性 | Gemini 對話式 | 傳統程式 |
|------|---------------|----------|
| 進度記錄 | ❌ 依賴對話歷史 | ✅ 寫入檔案 |
| 錯誤日誌 | ❌ 分散在對話中 | ✅ 集中在 log 檔 |
| 斷點續傳 | ❌ 難以實作 | ✅ 讀取狀態檔即可 |
| 可追溯性 | ❌ 對話可能被清除 | ✅ 日誌永久保存 |

### 3.4 問題四：從未成功完成大量抓取

**現象**:
- 一次完整大量的抓取都沒有實現過

**根本原因（綜合以上問題）**:
```
Token 消耗 → 執行變慢 → 運行時間拉長
      ↓
   偶爾 API 空白 → 流程中斷 → 無法自動恢復
      ↓
   不知道卡在哪 → 人工介入困難 → 放棄重試
      ↓
   永遠無法完成一次完整的大量抓取
```

**數據證據**:
- `2025-10-14.jsonl`: 僅 5 筆資料
- `2025-10-18.jsonl`: 僅 1 筆資料
- 與「大量抓取」的目標相去甚遠

---

## 4. 深層問題分析

### 4.1 工具選擇的不匹配

**Gemini + MCP 的本質**:
- 這是一個**對話式 AI + 工具呼叫**的範式
- 適合**互動式探索**、**一次性任務**
- 不適合**長時間運行**、**大批量處理**

**類比**:
```
用 Gemini 爬蟲 = 用 ChatGPT 寫文章
- 寫一篇文章？完美！
- 寫一本 500 頁的書？不切實際

正確的做法：
- 用 AI 生成章節大綱
- 用程式自動化組裝、排版、產出
```

### 4.2 穩定性需求的衝突

**長時間運行系統的基本需求**:
1. ✅ 錯誤必須自動重試（而非人工介入）
2. ✅ 狀態必須持久化（而非依賴記憶）
3. ✅ 日誌必須完整（而非分散在對話中）
4. ✅ 流程必須可恢復（而非重頭來過）

**AI 對話式系統的特性**:
1. ❌ 錯誤需要使用者確認後才能重試
2. ❌ 狀態存在於對話上下文（可能被清除）
3. ❌ 日誌分散在對話歷史（難以結構化分析）
4. ❌ 流程依賴連續對話（中斷即失效）

**結論**: 這是**工具特性**與**任務需求**的根本性不匹配。

---

## 5. 為何不能只「改進」Gemini 方案？

### 5.1 嘗試改進的困難

**可能的改進方向**:
1. "讓 Gemini 加入重試邏輯" → 會進一步增加 Token 消耗
2. "讓 Gemini 記錄進度" → 仍依賴對話上下文，不可靠
3. "讓 Gemini 寫日誌" → 每次呼叫 MCP 寫檔又消耗 Token
4. "讓 Gemini 分批執行" → 需要使用者在每批之間手動介入

**核心矛盾**: 每一個改進都會**加劇** Token 消耗問題。

### 5.2 邊際效益遞減

```
投入時間調整 Gemini 方案 → 微小改進 → 仍無法穩定運行
         vs
投入時間建立傳統程式 → 一次到位 → 穩定可靠
```

**Regret Minimization 視角**:
- 繼續修補 Gemini 方案 = 可能浪費時間卻無法根本解決
- 建立獨立程式化方案 = 即使失敗也留下完整文檔和可用工具

---

## 6. 需要什麼樣的解決方案？

### 6.1 核心需求清單

| 需求 | Gemini 方案 | 理想方案 |
|------|-------------|----------|
| **Zero Token Cost** | ❌ 每次都消耗 | ✅ 純程式執行 |
| **自動重試** | ❌ 需人工確認 | ✅ 程式自動處理 |
| **狀態持久化** | ❌ 依賴對話 | ✅ 寫入檔案 |
| **完整日誌** | ❌ 分散在對話 | ✅ 結構化 log 檔 |
| **斷點續傳** | ❌ 難以實作 | ✅ 讀取狀態檔 |
| **可監控** | ❌ 需持續對話 | ✅ 獨立監控介面 |
| **無人值守** | ❌ 需定期介入 | ✅ 可背景運行 |

### 6.2 技術方案要求

1. **必須使用傳統程式語言**: Python, Node.js, etc.
2. **必須有狀態管理**: JSON/SQLite 存狀態
3. **必須有日誌系統**: Python logging 或類似
4. **必須可獨立運行**: 不依賴 AI 對話
5. **必須整合現有系統**: 呼叫 `save_rental_v8.py`

---

## 7. 為何選擇 Claude 接手？

### 7.1 Claude 的定位差異

**Claude 在此專案的角色**:
- ❌ 不是在運行時持續參與（那會重蹈覆轍）
- ✅ 是在開發時撰寫程式碼
- ✅ 產出的是**純 Python 程式**，之後無需 Claude 參與

**類比**:
```
Gemini 方案 = 請 AI 廚師每天幫你做飯（持續成本）
Claude 方案 = 請 AI 工程師幫你建自動化廚房（一次性投入）
```

### 7.2 為何不用其他方式？

**選項 A: 人工寫程式**
- ✅ 最可控
- ❌ 需要使用者具備開發能力
- ❌ 時間成本高

**選項 B: 使用現成爬蟲工具**
- ✅ 可能較快
- ❌ 通用工具難以適配 Facebook 特殊需求
- ❌ 仍需寫整合程式碼

**選項 C: Claude 開發專用程式 (本方案)**
- ✅ 客製化符合需求
- ✅ 完整文檔（可維護）
- ✅ 獨立運行（不依賴 AI）
- ⚠️ 需投入時間規劃和測試

---

## 8. 風險與限制

### 8.1 Claude 方案的潛在風險

1. **Facebook 反爬蟲機制**
   - 風險: 帳號被封鎖
   - 緩解: 降低速度、模擬真人行為

2. **開發時間投入**
   - 風險: 花費數天開發仍可能失敗
   - 緩解: 完整文檔確保知識留存

3. **維護成本**
   - 風險: Facebook UI 改版導致失效
   - 緩解: 模組化設計、定期測試

### 8.2 不解決方案的風險

**如果不建立獨立程式化方案**:
- ❌ Gemini 方案問題持續存在
- ❌ 無法實現大規模資料抓取
- ❌ 專案目標無法達成
- ❌ 已投入的時間和 Next.js App 無法發揮價值

---

## 9. 結論

### 9.1 問題本質

Gemini 的方案不是「做錯了」，而是**工具特性與任務需求的不匹配**：
- 對話式 AI 適合**互動探索**
- 大規模爬蟲需要**穩定自動化**

### 9.2 解決方向

需要一個**純程式化的、獨立運行的、可監控的**爬蟲系統：
- Zero AI Token 消耗
- 完整錯誤處理與重試
- 狀態持久化與斷點續傳
- 結構化日誌與監控

### 9.3 Claude 的角色

Claude 作為**開發者**（而非運行者），協助：
1. 設計系統架構
2. 撰寫 Python 程式碼
3. 建立完整文檔
4. 產出一個**可獨立運行**的工具

### 9.4 成功標準

當以下情況發生時，我們知道問題已解決：
- ✅ 能夠無人值守運行 2+ 小時
- ✅ 成功抓取 500+ 則貼文
- ✅ 所有錯誤都有日誌記錄
- ✅ 中斷後可自動恢復
- ✅ 使用者不需要 AI 協助即可運行

---

**文件結束**

下一步請閱讀: `02_solution_design.md`
